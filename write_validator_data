#!/usr/bin/env python3

# standard imports
import argparse
import json
import numpy
import os
import sys
import tempfile
import time

# Import local subnet_data module
sys.path = [os.path.join(os.path.dirname(__file__), "python")] + sys.path


LOCAL_TIMEZONE = "MST7MDT"
JSON_FILE_NAME = "validator_data.json"
TIMESTAMP_FILE_NAME = "timestamp.json"
LOCAL_SUBTENSORS = [
    "cali",
    "candyland",
    "la",
    "moonbase",
    "titan",
]
LOCAL_SUBTENSOR_ROTATE_ARG = "rotate"


def _parse_args():
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "-j", "--json-folder",
        required=True,
        help="The json folder in which to write the json files.")

    parser.add_argument(
        "-l", "--local-subtensor",
        help="Use the specified local subtensor (i.e. la, cali, titan, etc.). "
             f"Specify '{LOCAL_SUBTENSOR_ROTATE_ARG}' to rotate between all local "
             "subtensors. When not specified, use the 'finney' network subtensor.")

    procs_or_chunks = parser.add_mutually_exclusive_group()

    procs_or_chunks.add_argument(
        "-c", "--chunks",
        type=int,
        default=0,
        help="The number of chunks. Each chunk will write a different json file "
             "for a range of validators. This is only valid when not multi-processing.")

    parser.add_argument(
        "-o", "--run-once",
        action="store_true",
        help="When specified, the data gathering and json write happnes only once.")

    parser.add_argument(
        "-i", "--interval",
        type=float,
        default=5,
        help="The number of minutes between validator data gathering.")

    return parser.parse_args()


def format_time(total_time):
    m = total_time/60
    minutes = int(m)
    seconds = round((m - minutes)*60)

    runtime_text = [f"{minutes} minutes"] if minutes else []
    if seconds:
        runtime_text += [f"{seconds} seconds"]
    runtime_text = ", ".join(runtime_text)

    return runtime_text


def write_json_file(
        network, all_subnets, json_folder, netuid_start=None, netuid_end=None
    ):
    print("Gathering subnet data.")
    start_time = time.time()

    if netuid_start is not None:
        if netuid_end is not None:
            netuids = all_subnets[netuid_start:netuid_end+1]
        else:
            netuids = all_subnets[netuid_start:]
    else:
        netuids = all_subnets[1:]

    netuid_range = f"{netuids[0]}-{netuids[-1]}"
    json_base, json_ext = os.path.splitext(JSON_FILE_NAME)
    json_file_name = f"{json_base}.{netuid_range}{json_ext}"
    json_file = os.path.join(json_folder, json_file_name)

    data_dict = SubnetData(netuids, network, True).to_dict()

    print(f"\nWriting data to file: {json_file}")
    with open(json_file, "w") as fd:
        json.dump(data_dict, fd, indent=4)

    total_time = time.time() - start_time
    print(f"\nSubnet data gathering took {format_time(round(total_time))}.\n")


def write_timestamp(json_folder):
    os.environ["TZ"] = LOCAL_TIMEZONE
    time.tzset()

    max_file_time = 0
    json_base, json_ext = os.path.splitext(JSON_FILE_NAME)
    for _file in os.listdir(json_folder):
        file_base, file_ext = os.path.splitext(_file)
        if not file_base.startswith(json_base) or file_ext != json_ext:
            continue

        json_file = os.path.join(json_folder, _file)
        file_time = os.path.getmtime(json_file)
        if file_time > max_file_time:
            max_file_time = file_time
    
    timestamp = time.ctime(max_file_time)
    timestamp_file = os.path.join(json_folder, TIMESTAMP_FILE_NAME)
    print(f"\nWriting timestamp file: {timestamp_file}")
    with open(timestamp_file, "w") as fd:
            json.dump(timestamp, fd)


def get_netuid_start_end_args(num_subnets, num_chunks):
    chunk_size = int(numpy.ceil(num_subnets / num_chunks))
    netuid_start = 1
    while True:
        netuid_end = netuid_start + chunk_size - 1
        if netuid_end >= num_subnets:
            yield netuid_start, None
            break
        yield netuid_start, netuid_end
        netuid_start = netuid_end + 1


def get_network(local_subtensor, local_subtensor_index):
    network_name = (
        LOCAL_SUBTENSORS[local_subtensor_index]
        if local_subtensor == LOCAL_SUBTENSOR_ROTATE_ARG
        else local_subtensor
    )

    return (
        f"ws://subtensor-{network_name}.rizzo.network:9944"
        if network_name
        else "finney"
    )


def main(options):
    os.makedirs(options.json_folder, exist_ok=True)

    local_subtensor_index = -1
    interval_seconds = round(options.interval * 60)

    while True:
        start_time = time.time()
        local_subtensor_index = (local_subtensor_index + 1) % len(LOCAL_SUBTENSORS)
        network = get_network(options.local_subtensor, local_subtensor_index)
        all_subnets = bittensor.subtensor(network=network).get_subnets()
        tempdir = tempfile.mkdtemp(prefix="write_vali_data_")

        if options.chunks:
            num_subnets = len(all_subnets) - 1
            for i, (netuid_start, netuid_end) in enumerate(
                get_netuid_start_end_args(num_subnets, options.chunks)
            ):
                if i > 0:
                    time.sleep(2)
                write_json_file(
                    network, all_subnets, tempdir, netuid_start, netuid_end
                )
        else:
            write_json_file(network, all_subnets, tempdir)

        # Copy files over to relevant location
        for file_name in os.listdir(options.json_folder):
            json_file = os.path.join(options.json_folder, file_name)
            if (
                not os.path.isfile(json_file)
                or os.path.splitext(json_file)[1] != ".json"
            ):
                continue
            print(f"Removing {json_file}")
            os.unlink(json_file)
        for file_name in os.listdir(tempdir):
            src_json_file = os.path.join(tempdir, file_name)
            dest_json_file = os.path.join(options.json_folder, file_name)
            print(f"Moving {src_json_file} to {dest_json_file}")
            os.rename(src_json_file, dest_json_file)

        os.rmdir(tempdir)

        write_timestamp(options.json_folder)

        if options.run_once:
            break

        total_seconds = round(time.time() - start_time)
        wait_seconds = interval_seconds - total_seconds
        if wait_seconds > 0:
            wait_time_formatted = format_time(wait_seconds)
            print(f"Waiting {wait_time_formatted}.")
            time.sleep(wait_seconds)


if __name__ == "__main__":
    options = _parse_args()

    # bittensor import
    import bittensor

    # Import local subnet_data module
    from subnet_data import SubnetData

    main(options)
